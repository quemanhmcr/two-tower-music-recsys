import faiss
import torch
import numpy as np
import os
from torch.utils.data import DataLoader

def test_retrieval(trainer, config, top_k=10):
    """
    Sanity Check: Kiá»ƒm tra cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh báº±ng máº¯t thÆ°á»ng (Qualitative Evaluation).
    
    Logic:
    1. Láº¥y ngáº«u nhiÃªn 1 User tá»« táº­p Validation.
    2. Sinh User Vector báº±ng User Tower.
    3. Truy váº¥n (Query) vÃ o FAISS Index Ä‘á»ƒ tÃ¬m Top-K Item tÆ°Æ¡ng Ä‘á»“ng nháº¥t.
    4. Hiá»ƒn thá»‹ káº¿t quáº£ kÃ¨m tráº¡ng thÃ¡i (Re-listen hay New Discovery) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ sÆ¡ bá»™ Ä‘á»™ há»£p lÃ½.
    """
    print("ğŸ” STARTING RETRIEVAL TEST...")

    # 1. Load FAISS Index
    index_path = f"{config.CHECKPOINT_DIR}/item_vectors_256d.faiss"
    if not os.path.exists(index_path):
        print(f"âŒ Error: File index khÃ´ng tá»“n táº¡i táº¡i {index_path}")
        return

    print(f"   ğŸ“‚ Loading Index from: {index_path}")
    try:
        index = faiss.read_index(index_path)
        print(f"   âœ… Index loaded. Total Items: {index.ntotal:,}")
    except Exception as e:
        print(f"âŒ Lá»—i load index: {e}")
        return

    # 2. Láº¥y 1 Batch User (FIX Lá»–I ZOMBIE PROCESS)
    print("\nğŸ‘¤ Generating User Vector...")
    try:
        # [FIX] Táº¡o loader táº¡m vá»›i num_workers=0 Ä‘á»ƒ trÃ¡nh lá»—i multiprocessing cleanup
        # Ta tÃ¡i sá»­ dá»¥ng dataset cá»§a val_loader cÅ©
        temp_loader = DataLoader(
            trainer.val_loader.dataset,
            batch_size=1,
            shuffle=True,
            num_workers=0 # <--- QUAN TRá»ŒNG: Cháº¡y trÃªn main process
        )
        batch = next(iter(temp_loader))

        device = trainer.device
        batch = {k: v.to(device) for k, v in batch.items()}

        # Cháº¡y User Tower
        user_tower = trainer.model.user_tower
        user_tower.eval()

        with torch.no_grad():
            user_embeddings = user_tower(batch)
            query_vector = user_embeddings[0].cpu().numpy().reshape(1, -1)

    except Exception as e:
        print(f"âŒ Lá»—i sinh user vector: {e}")
        return

    # 3. Search & Print Results
    print(f"\nğŸ” Searching Top-{top_k} recommendations...")
    D, I = index.search(query_vector, top_k)

    print("\n" + "="*50)
    print("ğŸ¯ RECOMMENDATION RESULTS")
    print("="*50)

    history_ids = batch['seq_item_ids'][0].cpu().numpy()
    history_ids = history_ids[history_ids > 0] # Bá» padding

    print(f"User History (Last 5): {history_ids[-5:]}")
    print("-" * 65)
    print(f"{'Rank':<5} | {'Item ID':<12} | {'Score':<10} | {'Status'}")
    print("-" * 65)

    for rank, (idx, score) in enumerate(zip(I[0], D[0])):
        real_item_id = idx + 1
        status = "ğŸ§ Re-listen" if real_item_id in history_ids else "âœ¨ New"
        print(f"{rank+1:<5} | {real_item_id:<12} | {score:.4f}     | {status}")

    print("="*50)
